{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDDGVPbsPJKnYxW0LgolkA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GOVINDFROMINDIA/Toxic_Comment_Classification/blob/main/Toxic_Comment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOXIC COMMENT CLASSIFICATION "
      ],
      "metadata": {
        "id": "21dSR6i198U2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y1O3kSF470EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5af89a7-ef42-434c-adca-014884cdea95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data also has additional toxicity subtype attributes: (Model does not have to predict these)**\n",
        "- severe_toxicity\n",
        "- obscene\n",
        "- threat\n",
        "- insult\n",
        "- identity_attack\n",
        "- sexual_explicit\n",
        "\n",
        "### **Comment_text data also has identity attributes carved out from it, some of which are:**\n",
        "- male\n",
        "- female\n",
        "- homosexual_gay_or_lesbian\n",
        "- christian\n",
        "- jewish\n",
        "- muslim\n",
        "- black\n",
        "- white\n",
        "- asian\n",
        "- latino\n",
        "- psychiatric_or_mental_illness"
      ],
      "metadata": {
        "id": "Cwyp_dSPBqyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_toxic(token):\n",
        "  toxicity=0\n",
        "  for i in len(token):\n",
        "    if is_sexual_explicit(i):\n",
        "      toxicity+=1\n",
        "    if is_obscene(i):\n",
        "      toxicity+=1\n",
        "    if is_threat(i):\n",
        "      toxicity+=1\n",
        "    if is_insult(i):\n",
        "      toxicity+=1\n",
        "    if is_identity_attack(i):\n",
        "      toxicity+=1\n",
        "  if toxicity>=1:\n",
        "    if toxicity >=2:\n",
        "      print(\"Severe toxicity: You Cannot put any comment again\")\n",
        "      return 2\n",
        "    else:\n",
        "      print(\"Toxic Comment; pls don't \")\n",
        "      return 1\n",
        "    else:\n",
        "      return 0"
      ],
      "metadata": {
        "id": "cioyDuIw97Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MAIN\n",
        "running=0\n",
        "comments=[]\n",
        "while running >=0:\n",
        "  yn=input(\"Do you wish to have a comment: \")\n",
        "  if yn.lower()==\"yes\" or yn.lower()==\"y\":\n",
        "    if running >0:\n",
        "      sentence=input(\"Your Comment has been saved; Enter your next comment: \")\n",
        "    elif running==0:\n",
        "      sentence=input(\"Enter your first comment: \")\n",
        "      running+=1\n",
        "      tokens = nltk.word_tokenize(sentence)\n",
        "      if is_toxic(tokens)==1:\n",
        "        sentence=\"Halmful Comment detected, report sent!\"\n",
        "        print(sentence)\n",
        "        comments.append(sentence)\n",
        "      elif is_toxic(tokens)==2 :\n",
        "        running=-1\n",
        "        sentence=\"Blocked from further Commenting\"\n",
        "        print(sentence)\n",
        "        comments.append(sentence)\n",
        "      elif is_toxic(tokens)==0 :\n",
        "        comments.append(sentence)\n",
        "  if yn.lower()==\"no\" or yn.lower()==\"n\":\n",
        "    print(\"Thank you! \")\n",
        "    running=-1\n",
        "    break\n",
        "\n",
        "print(\"-\"*10)\n",
        "print(\"Comment History\")\n",
        "if len(comments)>0:\n",
        "  for i in range(len(comments)):\n",
        "    print(\"Comment\",i+1,\" is: \",comments[i])\n",
        "else:\n",
        "  print(\"No comment registered\")\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YNfk40rEvHM",
        "outputId": "562caef6-5c68-4f89-87aa-5bc9dbda05fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you wish to have a comment: y\n",
            "Enter your first comment: hi\n",
            "Do you wish to have a comment: y\n",
            "Your Comment has been saved; Enter your next comment: govind has failed\n",
            "Do you wish to have a comment: y\n",
            "Your Comment has been saved; Enter your next comment: byebye!\n",
            "Do you wish to have a comment: n\n",
            "Thank you! \n",
            "Comment 1  is:  hi\n",
            "Comment 2  is:  govind has failed\n",
            "Comment 3  is:  byebye!\n"
          ]
        }
      ]
    }
  ]
}